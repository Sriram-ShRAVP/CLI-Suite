import socket
from scapy.all import ARP, Ether, srp
import requests
from bs4 import BeautifulSoup

# Simulated Network Scanner
def network_scanner():
    print("\n[+] Simulated Network Scanner...")
    ip_range = input("Enter the IP range to scan (e.g., 192.168.1.1-5): ")
    ip_base = ip_range.split('-')[0][:-1]
    start = int(ip_range.split('.')[-1].split('-')[0])
    end = int(ip_range.split('-')[-1]) + 1

    for ip_end in range(start, end):
        ip = f"{ip_base}{ip_end}"
        try:
            socket.gethostbyaddr(ip)
            print(f"Host found: {ip}")
        except socket.herror:
            continue

# Simulated Vulnerability Scanner
def vulnerability_scanner():
    print("\n[+] Simulated Vulnerability Scanner...")
    ip = input("Enter the IP address to scan: ")
    common_ports = [22, 80, 443]
    for port in common_ports:
        try:
            with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as sock:
                sock.settimeout(1)
                result = sock.connect_ex((ip, port))
                if result == 0:
                    print(f"Port {port} is open on {ip}.")
                    # Simulate a basic vulnerability check
                    if port == 80:
                        print(f"-> Possible vulnerability: Unencrypted HTTP traffic on port {port}.")
                else:
                    print(f"Port {port} is closed on {ip}.")
        except socket.error as e:
            print(f"Couldn't connect to {ip}:{port}. Error: {e}")

# List Available IPs
def list_available_ips():
    print("\n[+] Listing Available IPs on the Network...")
    target_ip = input("Enter the target IP range (e.g., 192.168.1.1/24): ")
    arp = ARP(pdst=target_ip)
    ether = Ether(dst="ff:ff:ff:ff:ff:ff")
    packet = ether/arp
    result = srp(packet, timeout=3, verbose=0)[0]
    print("Available devices in the network:")
    print("IP" + " "*18 + "MAC")
    for sent, received in result:
        print("{:16}    {}".format(received.psrc, received.hwsrc))

# Web Crawler
def web_crawler():
    print("\n[+] Starting Web Crawler...")
    url = input("Enter the URL to crawl: ")
    try:
        response = requests.get(url)
        soup = BeautifulSoup(response.text, 'html.parser')
        print("Found URLs:")
        for link in soup.find_all('a'):
            href = link.get('href')
            if href and not href.startswith('#'):
                print(href)
    except requests.exceptions.RequestException as e:
        print(f"Error: {e}")

# Main Menu
def main_menu():
    while True:
        print("\nPenetration Testing Suite")
        print("1. List Available IPs")
        print("2. Network Scanner")
        print("3. Vulnerability Scanner")
        print("4. Web Crawler")
        print("5. Exit")
        choice = input("Enter your choice (1-5): ")

        if choice == '1':
            list_available_ips()
        elif choice == '2':
            network_scanner()
        elif choice == '3':
            vulnerability_scanner()
        elif choice == '4':
            web_crawler()
        elif choice == '5':
            print("Exiting...")
            break
        else:
            print("Invalid choice. Please try again.")

if __name__ == "__main__":
    main_menu()